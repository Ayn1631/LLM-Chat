{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf62bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Any\n",
    "from langchain.evaluation import load_evaluator, EvaluatorType\n",
    "import langchain\n",
    "from langchain_community.cache import InMemoryCache\n",
    "langchain.llm_cache = InMemoryCache()\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 加载环境变量\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f5b6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful load embedding model\n",
      "successful load rerank model\n",
      "~ 正在读取文本\n",
      "~ 正在添加进知识库\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BM25 Embedding:   0%|          | 0/302 [00:00<?, ?step/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\20753\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.757 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "BM25 Embedding: 100%|██████████| 302/302 [00:01<00:00, 234.05step/s]\n",
      "Annoy Embedding: 100%|██████████| 302/302 [00:10<00:00, 29.60step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ 添加成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from bge_RAG import RAG\n",
    "rag = RAG()\n",
    "rag.add()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56114427",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGEvaluator:\n",
    "    def __init__(self, api_key: str = None, criteria: Dict = None):\n",
    "        \"\"\"初始化RAG评估器\"\"\"\n",
    "        # 设置OpenAI API密钥\n",
    "        self.llm = ChatOpenAI(model=os.environ[\"Model\"], temperature=float(os.environ['temperature']))\n",
    "            \n",
    "        # 加载评估器\n",
    "        self.accuracy_evaluator = load_evaluator(EvaluatorType.QA, llm=self.llm)\n",
    "        \n",
    "        # 自定义评估标准\n",
    "        if criteria:\n",
    "            self.criteria_evaluator = load_evaluator(\n",
    "                EvaluatorType.LABELED_CRITERIA, \n",
    "                criteria=criteria,\n",
    "                llm=self.llm\n",
    "            )\n",
    "        else:\n",
    "            # 默认评估标准\n",
    "            self.criteria_evaluator = load_evaluator(\n",
    "                EvaluatorType.LABELED_CRITERIA,\n",
    "                criteria={\n",
    "                    \"正确性\": \"答案是否正确且事实一致\",\n",
    "                    \"完整性\": \"答案是否包含所有必要信息\",\n",
    "                    \"清晰度\": \"答案是否清晰易懂\",\n",
    "                    \"简洁性\": \"答案是否简洁明了，避免冗余\"\n",
    "                },\n",
    "                llm=self.llm\n",
    "            )\n",
    "            \n",
    "        # 初始化LLM（用于评估）\n",
    "        \n",
    "\n",
    "    def evaluate_answers(self, result_path: str, llm_rag_func) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        评估RAG系统的回答质量\n",
    "        \n",
    "        参数:\n",
    "            result_path: 结果JSON文件路径\n",
    "            llm_rag_func: RAG系统的调用函数，输入问题，返回回答\n",
    "            \n",
    "        返回:\n",
    "            包含评估结果的列表\n",
    "        \"\"\"\n",
    "        # 读取结果文件\n",
    "        with open(result_path, 'r', encoding='utf-8') as f:\n",
    "            results = json.load(f)\n",
    "            \n",
    "        evaluation_results = []\n",
    "        from tqdm import tqdm\n",
    "        results = results[:10]\n",
    "        for item in tqdm(results, desc=\"Evaluating\"):\n",
    "            question = item[\"question\"]\n",
    "            references = [item[f\"answer_{i+1}\"] for i in range(5) if f\"answer_{i+1}\" in item]\n",
    "            \n",
    "            # 调用RAG系统获取回答\n",
    "            llm_answer = llm_rag_func(question)\n",
    "            \n",
    "            # 评估回答\n",
    "            eval_result = self._evaluate_single_answer(question, llm_answer, references)\n",
    "            evaluation_results.append({\n",
    "                \"question\": question,\n",
    "                \"predicted_answer\": llm_answer,\n",
    "                \"evaluation\": eval_result\n",
    "            })\n",
    "            \n",
    "        return evaluation_results\n",
    "\n",
    "    def _evaluate_single_answer(self, question: str, predicted_answer: str, references: List[str]) -> Dict:\n",
    "        \"\"\"评估单个回答\"\"\"\n",
    "        # 1. 计算准确性评分\n",
    "        accuracy_result = self.accuracy_evaluator.evaluate_strings(\n",
    "            prediction=predicted_answer,\n",
    "            reference=references[0],  # 使用第一个参考答案\n",
    "            input=question\n",
    "        )\n",
    "        \n",
    "        # 2. 计算自定义标准评分\n",
    "        criteria_result = self.criteria_evaluator.evaluate_strings(\n",
    "            prediction=predicted_answer,\n",
    "            reference=references[0],  # 使用第一个参考答案\n",
    "            input=question\n",
    "        )\n",
    "        \n",
    "        # 3. 计算与其他参考答案的相似度\n",
    "        similarity_scores = []\n",
    "        for ref in references:\n",
    "            if ref.strip():  # 跳过空的参考答案\n",
    "                similarity = self._calculate_similarity(predicted_answer, ref)\n",
    "                similarity_scores.append(similarity)\n",
    "        \n",
    "        # 4. 合并评估结果\n",
    "        return {\n",
    "            \"accuracy\": accuracy_result.get(\"value\", \"UNKNOWN\"),\n",
    "            \"accuracy_score\": accuracy_result.get(\"score\", None),\n",
    "            \"accuracy_reasoning\": accuracy_result.get(\"reasoning\", \"\"),\n",
    "            \n",
    "            \"criteria\": criteria_result,\n",
    "\n",
    "            \"avg_similarity\": sum(similarity_scores) / len(similarity_scores) if similarity_scores else 0,\n",
    "            \"num_references\": len(references)\n",
    "        }\n",
    "\n",
    "\n",
    "    def _calculate_similarity(self, text1: str, text2: str) -> float:\n",
    "        \"\"\"计算两个文本的相似度（简化版）\"\"\"\n",
    "        # 在实际应用中，可以使用更复杂的相似度计算方法\n",
    "        # 这里使用简单的字符匹配率作为示例\n",
    "        common_chars = set(text1) & set(text2)\n",
    "        total_chars = set(text1 + text2)\n",
    "        return len(common_chars) / len(total_chars) if total_chars else 0\n",
    "\n",
    "    def generate_report(self, evaluation_results: List[Dict], output_path: str = \"evaluation_report.json\") -> None:\n",
    "        \"\"\"生成评估报告\"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(evaluation_results, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "        # 计算总体指标\n",
    "        total_items = len(evaluation_results)\n",
    "        correct_items = sum(1 for r in evaluation_results if r[\"evaluation\"][\"accuracy\"].lower() == \"correct\")\n",
    "        \n",
    "        print(f\"评估完成！共评估 {total_items} 个问题\")\n",
    "        print(f\"准确率: {correct_items/total_items:.2%}\")\n",
    "        print(f\"评估报告已保存至: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b3b71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化评估器\n",
    "evaluator = RAGEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b2a48e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自动模式下中央显示屏有两种切换方式：1.日出到日落：白天日间模式，晚上夜间模式；2.自定时段：按设置时间段切换。\n"
     ]
    }
   ],
   "source": [
    "import langchain.cache\n",
    "from langchain_core.runnables import RunnableSequence, RunnableMap, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 定义 RAG 工作流\n",
    "def create_rag_workflow():\n",
    "    # 定义 LLM\n",
    "    llm = ChatOpenAI(model=os.environ[\"Model\"], temperature=int(os.environ['temperature']))\n",
    "\n",
    "    # 定义输出解析器\n",
    "    output_parser = StrOutputParser()\n",
    "\n",
    "    # 定义 RAG 请求逻辑\n",
    "    def rag_request_logic(inputs):\n",
    "        user_input = inputs['user_input']\n",
    "        content = rag.req(user_input, top_k=5)\n",
    "        return {\"Unstructured\": content, \"user_input\": user_input}\n",
    "\n",
    "    # 定义 Prompt 格式化逻辑\n",
    "    def format_prompt(inputs):\n",
    "        prompt = '''你是一个智能问答系统, 你会完全按照用户的要求进行返回.你的输出应该在描述清楚的情况下尽可能简短!不需要Markdown格式, 不需要打招呼等礼貌用语!\n",
    "        ---需求\n",
    "        你会根据知识库的查询内容(Unstructured documents) 和对话历史信息进行智能回答.\n",
    "        - Unstructured documents:\n",
    "        {Unstructured}\n",
    "        --- 输入:\n",
    "        {user_input}\n",
    "        --- 输出:'''\n",
    "        return prompt.format(**inputs)\n",
    "\n",
    "    # 构建工作流\n",
    "    workflow = RunnableLambda(rag_request_logic)|\\\n",
    "        RunnableLambda(format_prompt)|\\\n",
    "        llm | output_parser\n",
    "        \n",
    "    \n",
    "    return workflow\n",
    "\n",
    "# 创建工作流\n",
    "workflow = create_rag_workflow()\n",
    "\n",
    "# 执行工作流\n",
    "user_input = '自动模式下，中央显示屏是如何切换日间和夜间模式的？'\n",
    "result = workflow.invoke({\"user_input\": user_input})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3dd2702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [02:28<00:00, 14.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# 模拟RAG系统\n",
    "def mock_rag_function(question: str) -> str:\n",
    "    # 这里应该调用你的RAG系统\n",
    "    # 为了演示，我们简单返回一个预设答案\n",
    "    return workflow.invoke({\"user_input\": question})\n",
    "\n",
    "# 评估\n",
    "results = evaluator.evaluate_answers(\n",
    "    result_path=\"data/result.json\",\n",
    "    llm_rag_func=mock_rag_function\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13f35b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评估完成！共评估 10 个问题\n",
      "准确率: 80.00%\n",
      "评估报告已保存至: evaluation_report.json\n"
     ]
    }
   ],
   "source": [
    "# 生成报告\n",
    "evaluator.generate_report(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774cc7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据知识库内容，关闭座椅加热功能可通过以下两种方式实现：\n",
      "\n",
      "**方法一：通过中央显示屏**\n",
      "1. 点击中央显示屏中的「座舱体验-座椅」，进入座椅设置界面。\n",
      "2. 选择驾驶员或副驾驶员侧座椅加热控制界面。\n",
      "3. 点击加热强度控制开关，循环切换至「关」状态。\n",
      "\n",
      "**方法二：通过Lynk&Co App**\n",
      "1. 登录Lynk&Co App，找到前排座椅加热图标。\n",
      "2. 直接点击图标即可关闭加热功能（图标状态会同步显示开关状态）。\n",
      "\n",
      "**注意事项：**\n",
      "- 加热功能关闭后，座椅温度会逐渐恢复正常。\n",
      "- 若乘客存在身体感知障碍（如病人、残疾人等），建议全程禁用该功能以确保安全。\n",
      "\n",
      "两种方式均可即时生效，您可根据当前使用场景选择最便捷的操作方式。\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3ecb88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch126",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
